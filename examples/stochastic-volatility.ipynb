{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Stochastic volatility\n",
    "This Notebook demos how to construct a stochastic volatility model and fit it to data. We will use the precision model of G. Chacko and L. M. Viceira. `Dynamic consumption and portfolio choice with stochastic volatility in incomplete markets` given by\n",
    "\\begin{cases}\n",
    "\\mathrm{d}Y_t = \\left (\\mu + \\beta e^{-V_t} \\right ) \\mathrm{d}t + e^{-V_t/2} \\mathrm{d}W_t, \\\\\n",
    "\\mathrm{d}V_t = \\kappa \\left (\\gamma - V_t \\right ) \\mathrm{d}t + \\sigma \\mathrm{d}B_t, \\\\\n",
    "\\end{cases}\n",
    "where $\\mu, \\beta, \\gamma \\in \\mathbb{R}$, and $\\kappa, \\sigma \\in \\mathbb{R}_+$. $\\{W_t\\}$ and $\\{V_t\\}$ are two one-dimensional, assumed independent, Wiener processes. As the above model is defined in continuous time, we need to discretize it; we do so using the Euler-Maruyma scheme.\n",
    "\n",
    "We begin with importing the necessary libraries for defining the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfilter.timeseries import StateSpaceModel, EulerMaruyma, Observable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the governing dynamics. We assume that the initial distribution of the model is given by \n",
    "\\begin{equation}\n",
    "V_0 \\sim \\mathcal{N} \\left ( \\gamma, \\frac{\\sigma}{\\sqrt{2 \\kappa}} \\right ),\n",
    "\\end{equation}\n",
    "so that we get the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fh0(reversion, level, std):\n",
    "    return level\n",
    "\n",
    "\n",
    "def gh0(reversion, level, std):\n",
    "    return std / torch.sqrt(2 * reversion)\n",
    "\n",
    "\n",
    "def fh(x, reversion, level, std):\n",
    "    return reversion * (level - x)\n",
    "\n",
    "\n",
    "def gh(x, reversion, level, std):\n",
    "    return std\n",
    "\n",
    "\n",
    "def go(vol, level, beta):\n",
    "    return level # + beta * torch.exp(vol)\n",
    "\n",
    "\n",
    "def fo(vol, level, beta):\n",
    "    return torch.exp(-vol / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we shall define our model. In order to do so, we must specify priors for the different parameters. Given their support, we assume that\n",
    "\\begin{cases}\n",
    "    \\mu, \\gamma \\sim \\mathcal{N}(0, 1), \\\\\n",
    "    \\kappa, \\sim \\mathcal{E}(5), \\\\\n",
    "    \\sigma \\sim \\mathcal{E}(2)\n",
    "\\end{cases}\n",
    "and for simplicity that $\\beta \\triangleq 0$. To do this, we need to import the necessary distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Exponential, Normal, StudentT, Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the model in terms of code and get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "volparams = Exponential(5.), Normal(0., 1.), Exponential(2.)\n",
    "logvol = EulerMaruyma((fh0, gh0), (fh, gh), volparams, ndim=1, dt=1.)\n",
    "obs = Observable((go, fo), (Normal(0., 1.), 0.), StudentT(df=3))\n",
    "\n",
    "stockmodel = StateSpaceModel(logvol, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that defines the model. Next, we need a dataset to train on. We're just going to pick one of the stocks represented in the S&P500. We load the data using Quandl and get, starting from 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import numpy as np\n",
    "\n",
    "stock = 'HD'\n",
    "y = np.log(quandl.get('EOD/{:s}'.format(stock), start_date='2000-01-01', column_index=11, api_key='ze2MLfC5LTiv_yqaKx8T', transform='rdiff') + 1)\n",
    "y *= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the data to get an idea of its volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236050d87f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "y.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit the model to the given data, we need an algorithm. We shall use a combination of NESS and SMC$^2$. We use SMC$^2$ for the first part of the data set, and then switch to NESS. Furthermore, since we are using particle filters, we need to decide on which proposal to use - should we go with the Bootstrap or something more advanced? For this example, we will use a linearized version. Importing the relevant classes, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfilter.algorithms import NESSMC2, NESS\n",
    "from pyfilter.filters import SISR\n",
    "from pyfilter.proposals import Linearized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NESS: 100%|████████████████████████████████████████████████████████████████████████| 4787/4787 [25:30<00:00, 14.36it/s]\n",
      "NESS: 100%|████████████████████████████████████████████████████████████████████████| 4787/4787 [37:49<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = 10\n",
    "training = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "algs = list()\n",
    "for i in range(2):\n",
    "    filt = SISR(stockmodel.copy(), 50, proposal=Linearized())\n",
    "    \n",
    "    algs.append(\n",
    "        NESSMC2(filt, 1000, handshake=1000).initialize().fit(training)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyfilter.utils import normalize\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(4, figsize=(16, 9))\n",
    "\n",
    "for r, alg in enumerate(algs):\n",
    "    param = alg.filter.ssm.observable.theta[0]\n",
    "    weights = normalize(alg._ness._w_rec)\n",
    "\n",
    "    xrange, xvals = param.get_plottable(weights=weights, kernel='gaussian')\n",
    "    ax[0].plot(xrange, xvals, label='Filter {:d}'.format(r+1))\n",
    "\n",
    "    for i, param in enumerate(alg.filter.ssm.hidden.theta):\n",
    "        xrange, xvals = param.get_plottable(weights=weights, kernel='gaussian')\n",
    "        ax[i+1].plot(xrange, xvals, label='Filter {:d}'.format(r+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and predict the future distributions of returns and superimpose the actual returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "actualreturns = y.iloc[-predictions:].cumsum().values\n",
    "ax.plot(y.index[-predictions:], actualreturns, label='Actual returns')\n",
    "\n",
    "for i, alg in enumerate(algs):\n",
    "    px, py = alg.filter.predict(predictions)\n",
    "\n",
    "    cum_py = np.percentile(np.cumsum(py, axis=0), [1, 50, 99], axis=1).T\n",
    "\n",
    "    ax.plot(y.index[-predictions:], cum_py, 'r', alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
